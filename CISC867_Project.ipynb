{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "CISC867 Project.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyO7ARTEtYOFYXakEMozFPG4",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/annabellesauve/Empathy-Detection/blob/main/CISC867_Project.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "x8vLLI5pai9i",
        "outputId": "e69a5b4b-470d-43d7-dede-e2e0a077025f"
      },
      "source": [
        "! pip install transformers\n",
        "! pip install tensorflow_addons"
      ],
      "execution_count": 120,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: transformers in /usr/local/lib/python3.7/dist-packages (4.11.3)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.7/dist-packages (from transformers) (21.0)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from transformers) (2.23.0)\n",
            "Requirement already satisfied: tokenizers<0.11,>=0.10.1 in /usr/local/lib/python3.7/dist-packages (from transformers) (0.10.3)\n",
            "Requirement already satisfied: huggingface-hub>=0.0.17 in /usr/local/lib/python3.7/dist-packages (from transformers) (0.0.19)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.7/dist-packages (from transformers) (1.19.5)\n",
            "Requirement already satisfied: sacremoses in /usr/local/lib/python3.7/dist-packages (from transformers) (0.0.46)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.7/dist-packages (from transformers) (2019.12.20)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.7/dist-packages (from transformers) (3.3.0)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.7/dist-packages (from transformers) (6.0)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.7/dist-packages (from transformers) (4.62.3)\n",
            "Requirement already satisfied: importlib-metadata in /usr/local/lib/python3.7/dist-packages (from transformers) (4.8.1)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from huggingface-hub>=0.0.17->transformers) (3.7.4.3)\n",
            "Requirement already satisfied: pyparsing>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging>=20.0->transformers) (2.4.7)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata->transformers) (3.6.0)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (3.0.4)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (2021.5.30)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (2.10)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (1.24.3)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers) (1.0.1)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers) (7.1.2)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers) (1.15.0)\n",
            "Requirement already satisfied: tensorflow_addons in /usr/local/lib/python3.7/dist-packages (0.14.0)\n",
            "Requirement already satisfied: typeguard>=2.7 in /usr/local/lib/python3.7/dist-packages (from tensorflow_addons) (2.7.1)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vFSxvfY3TST8"
      },
      "source": [
        "import tensorflow as tf\n",
        "import tensorflow_addons as tfa\n",
        "from transformers import RobertaTokenizer, TFRobertaModel, TFRobertaForMaskedLM\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import math"
      ],
      "execution_count": 121,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-Qvu-Y1khPOT"
      },
      "source": [
        "Roberta documentation: https://huggingface.co/transformers/model_doc/roberta.html?highlight=roberta#tfrobertamodel"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Rnh08SdiTNuz"
      },
      "source": [
        "# Encoders"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HSXFyPK6VE0y",
        "outputId": "360029d2-7ebd-4b81-c067-0674cd96663c"
      },
      "source": [
        "# robertabase model initialization, from huggingface\n",
        "robertabase_tokenizer = RobertaTokenizer.from_pretrained('roberta-base', do_lower_case=True)\n",
        "robertabase_model = TFRobertaModel.from_pretrained('roberta-base')\n",
        "robertabase_maskedLM_model = TFRobertaForMaskedLM.from_pretrained('roberta-base')"
      ],
      "execution_count": 122,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some layers from the model checkpoint at roberta-base were not used when initializing TFRobertaModel: ['lm_head']\n",
            "- This IS expected if you are initializing TFRobertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing TFRobertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "All the layers of TFRobertaModel were initialized from the model checkpoint at roberta-base.\n",
            "If your task is similar to the task the model of the checkpoint was trained on, you can already use TFRobertaModel for predictions without further training.\n",
            "All model checkpoint layers were used when initializing TFRobertaForMaskedLM.\n",
            "\n",
            "All the layers of TFRobertaForMaskedLM were initialized from the model checkpoint at roberta-base.\n",
            "If your task is similar to the task the model of the checkpoint was trained on, you can already use TFRobertaForMaskedLM for predictions without further training.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "P4YhNHXlUSD8"
      },
      "source": [
        "**S Encoder**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-HnNhFP-UHyc"
      },
      "source": [
        "# def S_Encoder(seeker_post, id_SP, attention_SP):\n",
        "class S_Encoder(tf.Module):\n",
        "  def __init__(self):\n",
        "    super().__init__()\n",
        "\n",
        "  # def _init_weights(self, module):\n",
        "  #   # don't know what weights to use to initialize.. not much info \n",
        "  #   module.bias.data.zero_()\n",
        "  #   module.weight.data.fill_(1.0)\n",
        "  \n",
        "  def encode(self, seeker_post):\n",
        "    encoded_input = robertabase_tokenizer(seeker_post, return_tensors='tf')\n",
        "    return robertabase_model(encoded_input)\n",
        "    # input_ids = np.array(robertabase_tokenizer.encode(seeker_post, add_special_tokens=True))\n",
        "    # return robertabase_maskedLM_model(input_ids, labels=input_ids)\n",
        "    # inputs = robertabase_tokenizer(seeker_post_mask, return_tensors=\"tf\")\n",
        "    # inputs[\"labels\"] = robertabase_tokenizer(seeker_post, return_tensors=\"tf\")[\"input_ids\"]\n",
        "    # return robertabase_maskedLM_model(inputs)"
      ],
      "execution_count": 138,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8osFmUMfUYAu"
      },
      "source": [
        "**R Encoder**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1TfyIoGdUo4J"
      },
      "source": [
        "class R_Encoder(tf.Module):\n",
        "  def __init__(self):\n",
        "    super().__init__()\n",
        "\n",
        "  # def _init_weights(self, module):\n",
        "  #   # don't know what weights to use to initialize.. not much info \n",
        "  #   module.bias.data.zero_()\n",
        "  #   module.weight.data.fill_(1.0)\n",
        "\n",
        "  def encode(self, response_post):\n",
        "    encoded_input = robertabase_tokenizer(response_post, return_tensors='tf')\n",
        "    return robertabase_model(encoded_input)\n",
        "\n",
        "  # def encode_mask(response_post, response_post_mask):\n",
        "\n",
        "  #   inputs = robertabase_tokenizer(response_post_mask, return_tensors=\"tf\")[\"input_ids\"]\n",
        "  #   inputs[\"labels\"] = robertabase_tokenizer(response_post, return_tensors=\"tf\")[\"input_ids\"]\n",
        "  #   return robertabase_maskedLM_model(inputs)\n",
        "    "
      ],
      "execution_count": 124,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bpPvfISMXz3v"
      },
      "source": [
        "# Attention Layer"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "b7unvUoBobsC"
      },
      "source": [
        "# query = ei(R)\n",
        "# keys + values = ei(S)\n",
        "\n",
        "# attention(i)(ei(R), ei(S)) = softmax((ei(R)*ei(S))/sqrt(d))*ei(S)\n",
        "# d = 768\n",
        "\n",
        "# residual mapping hi(R) = ei(R) + a(i)(ei(R), ei(S))"
      ],
      "execution_count": 127,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JZPUBIT5py59"
      },
      "source": [
        "class AttentionLayer(tf.Module):\n",
        "  \n",
        "  def __init__(self):\n",
        "    super().__init__()\n",
        "\n",
        "  def attention(self, e_R, e_S, d):\n",
        "    a = tf.math.multiply(tf.nn.softmax(tf.math.divide(tf.math.multiply(e_R, e_S), math.sqrt(d))), e_R)\n",
        "    return a\n",
        "\n",
        "\n",
        "\n",
        "## dont know where this is used   \n",
        "def residual(e_R, e_S, d):\n",
        "  h = e_R + attention(e_R, e_S, d)\n",
        "  return h"
      ],
      "execution_count": 177,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dX96QMmWuaMc"
      },
      "source": [
        "# Models"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uZstaEEzuZx8"
      },
      "source": [
        "# three models for three communication mechanisms in EPITOME\n",
        "\n",
        "# emotional reaction\n",
        "# interpretation\n",
        "# exploration\n",
        "\n",
        "# BiEncoderAttentionWithRationaleClassification() in models.py\n",
        "class Model(tf.Module):\n",
        "\n",
        "  def __init__(self, hidden_dropout_prob=0.2, rationale_num_labels=2, empathy_num_labels= 3, hidden_size=768):\n",
        "    super().__init__()\n",
        "\n",
        "    self.hidden_dropout_prob = hidden_dropout_prob\n",
        "    self.rationale_classifier = tf.keras.layers.Dense(rationale_num_labels, activation=None)\n",
        "    self.attention = AttentionLayer()\n",
        "    self.rationale_num_labels = rationale_num_labels\n",
        "    self.empathy_num_labels = empathy_num_labels\n",
        "    self.empathy_classifier = () # need to figure what this is \n",
        "    self.r_encoder = R_Encoder()\n",
        "    self.s_encoder = S_Encoder()\n",
        "    self.hidden_size = hidden_size\n",
        "\n",
        "    # self.apply(self._init_weights)\n",
        "\n",
        "  def _init_weights(self, module):\n",
        "    # don't know what weights to use to initialize.. not much info \n",
        "    module.bias.data.zero_()\n",
        "    module.weight.data.fill_(1.0)\n",
        "  \n",
        "  def forward(self,\n",
        "\t\tinput_ids_SP=None,\n",
        "\t\tinput_ids_RP=None,\n",
        "\t\tattention_mask_SP=None,\n",
        "\t\tattention_mask_RP=None,\n",
        "\t\ttoken_type_ids_SP=None,\n",
        "\t\ttoken_type_ids_RP=None,\n",
        "\t\tposition_ids_SP=None,\n",
        "\t\tposition_ids_RP=None,\n",
        "\t\thead_mask_SP=None,\n",
        "\t\thead_mask_RP=None,\n",
        "\t\tinputs_embeds_SP=None,\n",
        "\t\tinputs_embeds_RP=None,\n",
        "\t\tempathy_labels=None,\n",
        "\t\trationale_labels=None,\n",
        "\t\tlambda_EI=1,\n",
        "\t\tlambda_RE=0.1,\n",
        "    SP=None,\n",
        "    RP=None\n",
        "    ):\n",
        "\n",
        "    output_SP = []\n",
        "    output_RP = []\n",
        "\n",
        "    for post in SP:\n",
        "      output_SP.append(self.s_encoder.encode(post))\n",
        "    \n",
        "    for post in RP:\n",
        "      output_RP.append(self.r_encoder.encode(post))\n",
        "\n",
        "    output = []\n",
        "\n",
        "    # print(output_RP[0])\n",
        "    for i in range(len(output_RP)):\n",
        "      attn = self.attention.attention(output_RP[i].pooler_output, output_SP[i].pooler_output, self.hidden_size)\n",
        "      output.append(tf.nn.dropout(attn, self.hidden_dropout_prob))\n",
        "\n",
        "    logits_empathy = self.empathy_classifier(output[:, 0, :])\n",
        "\n",
        "    output = dropout(output)\n",
        "    logits_rationales = self.rationale_classifier(output)\n",
        "\n",
        "    loss_function = tf.keras.losses.CategoricalCrossentropy()\n",
        "\n",
        "    loss_empathy = loss_function(logits_empathy.reshape(-1, empathy_num_labels), empathy_labels.reshape(-1))\n",
        "    loss_rationales = loss_function(logits_rationales.reshape(-1, rationale_num_labels), rationale_labels.reshape(-1))\n",
        "\n",
        "    overall_loss = lambda_E1 * loss_empathy + lambda_RE + loss_rationales\n",
        "\n",
        "    return (overall_loss, loss_empathy, loss_rationales, logits_empathy, logits_rationale)"
      ],
      "execution_count": 178,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RULsqYSOsGDs"
      },
      "source": [
        "# Empathy Identification"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sXn16w96sQRG"
      },
      "source": [
        "# pass representation of CLS token in residual response post h through linear layer to get empathy level (0, 1, 2)\n",
        "# do this for three models for three communication mechanisms in EPITOME\n",
        "\n",
        "# figure out how they get this in the actual model (not used right now)\n",
        "\n",
        "# EmpathyClassifier() in empathy_classifier.py\n",
        "class EmpathyClassifier():\n",
        "\n",
        "  def __init__(self):\n",
        "    self.tokenizer = robertabase_tokenizer\n",
        "    self.batch_size = 1\n",
        "\n",
        "    self.model_ER = Model()\n",
        "    self.model_IP = Model()\n",
        "    self.model_EX = Model() \n",
        "\n",
        "  def predict_empathy(self, seeker_posts, response_posts): \n",
        "\n",
        "    id_SP = [] # ids \n",
        "    id_RP = [] \n",
        "    attention_SP = [] # attention masks\n",
        "    attention_RP = []\n",
        "\n",
        "    # code provided on paper's github, adapted for tensorflow\n",
        "    for sent in seeker_posts: # tokenize the seeker posts\n",
        "      encoded_dict = self.tokenizer.encode_plus(\n",
        "          sent, \n",
        "          add_special_tokens = True, # add CLS and SEP tokens\n",
        "          max_length = 64,\n",
        "          pad_to_max_length = True,\n",
        "          return_attention_mask = True,\n",
        "          return_tensors = 'tf' # tensorflow tensors\n",
        "      )\n",
        "\n",
        "      id_SP.append(encoded_dict['input_ids'])\n",
        "      attention_SP.append(encoded_dict['attention_mask'])\n",
        "    \n",
        "    for sent in response_posts: # tokenize response posts\n",
        "      encoded_dict = self.tokenizer.encode_plus(\n",
        "          sent, \n",
        "          add_special_tokens = True, # add CLS and SEP tokens\n",
        "          max_length = 64,\n",
        "          pad_to_max_length = True,\n",
        "          return_attention_mask = True,\n",
        "          return_tensors = 'tf' # tensorflow tensore\n",
        "      )\n",
        "\n",
        "      id_RP.append(encoded_dict['input_ids'])\n",
        "      attention_RP.append(encoded_dict['attention_mask'])\n",
        "\n",
        "    id_SP = tf.concat(id_SP, 0)\n",
        "    id_RP = tf.concat(id_RP, 0)\n",
        "    attention_SP = tf.concat(attention_SP, 0)\n",
        "    attention_RP = tf.concat(attention_RP, 0)\n",
        "\n",
        "    # create dataset\n",
        "    dataset = tf.data.Dataset.from_tensors(input_SP, attention_SP, input_RP, attention_RP)\n",
        "\n",
        "    # evaluate\n",
        "    for element in dataset:\n",
        "      e_id_SP = element[0] # get seeker id \n",
        "      e_attention_SP = element[1] # get seeker attention \n",
        "      e_id_RP = element[2] # get response id \n",
        "      e_attention_RP = element[3] # get response attention\n",
        "\n",
        "      # _loss, _loss_e, _loss_r, logits_empathy_ER, logits_rationale_ER = self.model_ER(e_id_SP, e_attention_SP, e_id_RP, e_attention_RP, seeker_posts, response_posts)\n",
        "      # _loss, _loss_e, _loss_r, logits_empathy_IP, logits_rationale_IP = self.model_IP(e_id_SP, e_attention_SP, e_id_RP, e_attention_RP, seeker_posts, response_posts)\n",
        "      # _loss, _loss_e, _loss_r, logits_empathy_EX, logits_rationale_EX = self.model_EX(e_id_SP, e_attention_SP, e_id_RP, e_attention_RP, seeker_posts, response_posts)\n",
        "\n",
        "      prediction_ER = np.argmax(logits_empathy_ER, axis=1).flatten()\n",
        "      prediction_IP = np.argmax(logits_empathy_IP, axis=1).flatten()\n",
        "      prediction_EX = np.argmax(logits_empathy_EX, axis=1).flatten()\n",
        "    \n",
        "    return (logits_empathy_ER, predictions_ER, logits_empathy_IP, predictions_IP, logits_empathy_EX, predictions_EX)"
      ],
      "execution_count": 169,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gklgvsTWsJxL"
      },
      "source": [
        "# Rationale Extraction"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cKf2pGSHsZik"
      },
      "source": [
        "# pass representation of individual tokens in residual response post h through linear layer to make boolean prediction \n",
        "# also do this for three models for three communication mechanisms in EPITOME\n",
        "\n",
        "# i think this happens under model()"
      ],
      "execution_count": 131,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MEN6n86d7Pjj"
      },
      "source": [
        "# Initializing model + training"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tiWFQmucaU6s",
        "outputId": "bfe9356a-2fc3-4e64-e8ea-9791b961357e"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 132,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zPMI-feNa6kF"
      },
      "source": [
        "# load dataset\n",
        "  # assuming for now seeker posts is \"seeker_posts\" and reponse posts is \"response_posts\"\n",
        "df_ER = pd.read_csv('/content/drive/My Drive/emotionalreactions.csv')\n",
        "df_ER = df_ER.head(50) # temporary\n",
        "\n",
        "df_ER['response_post_masked'] = df_ER['response_post_masked'].replace(np.nan, 0)"
      ],
      "execution_count": 150,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tN-XIafgcEdn"
      },
      "source": [
        "# roberta domain adaptive pre training 3 epoch 8 batch\n",
        "\n",
        "# can't get this to work. the tfrobertaformaskedlm example doesn't even work.\n",
        "\n",
        "# optimizer_roberta = tfa.optimizers.AdamW(\n",
        "#     weight_decay=1e-2, # not given but default in py torch so probably used\n",
        "#     learning_rate=2e-5, # given\n",
        "#     epsilon=1e-8 # given\n",
        "# )\n",
        "\n",
        "# sp = df_ER.seeker_post \n",
        "# rp = df_ER.response_post\n",
        "# rp_masked = df_ER.response_post_masked\n",
        "\n",
        "# encoder_train_data = [sp, rp, rp_masked]\n",
        "\n",
        "# S_encoder_model = S_Encoder()\n",
        "# R_encoder_model = R_Encoder()\n",
        "\n",
        "# total_encoder_train_loss = 0\n",
        "# total_encoder_sp_loss = 0\n",
        "# total_encoder_rp_loss = 0\n",
        "\n",
        "# for epoch in range(0, 3):\n",
        "#   print(\"Training epoch #\", epoch, \"...\")\n",
        "\n",
        "#   for i in range(len(encoder_train_data[0])):\n",
        "#       e_sp = encoder_train_data[0][i] # seeker post \n",
        "#       e_rp = encoder_train_data[1][i] # response post \n",
        "#       e_rp_masked = encoder_train_data[2][i] # masked response post\n",
        "\n",
        "#       # sp_output = S_Encoder.encode(e_sp)\n",
        "#       if not isinstance(e_rp_masked, str):\n",
        "#         continue \n",
        "#       else:\n",
        "#         rp_output = R_Encoder.encode_mask(e_rp, e_rp_masked)\n",
        "\n",
        "#         print(rp_output)\n",
        "#         total_encoder_train_loss += rp_output.loss # what is total loss? no info\n",
        "#         # total_encoder_sp_loss += sp_output.loss\n",
        "#         total_encoder_rp_loss += rp_output.loss\n",
        "\n",
        "#         optimizer_roberta.minimize(rp_output.loss) # update optimizer\n",
        "\n",
        "#         print(rp_output.loss)\n",
        "    \n",
        "#   print(\"Epoch #\", epoch)\n",
        "#   print(\"Total loss:\", total_train_loss)\n",
        "#   print(\"Total empathy loss:\", total_train_empathy_loss)\n",
        "#   print(\"Total rationale loss:\", total_train_rationale_loss)"
      ],
      "execution_count": 134,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yB1PbYtl7V_o"
      },
      "source": [
        "# tokenize input \n",
        "tokenizer_RP = robertabase_tokenizer.batch_encode_plus(df_ER.response_post, add_special_tokens=True, max_length=64, padding='max_length', truncation=True)\n",
        "input_ids_RP = np.array(tokenizer_RP['input_ids'])\n",
        "attention_masks_RP = np.array(tokenizer_RP['attention_mask'])\n",
        "\n",
        "tokenizer_SP = robertabase_tokenizer.batch_encode_plus(df_ER.seeker_post, add_special_tokens=True, max_length=64, padding='max_length', truncation=True)\n",
        "input_ids_SP = np.array(tokenizer_SP['input_ids'])\n",
        "attention_masks_SP = np.array(tokenizer_RP['attention_mask'])\n",
        "\n",
        "labels = np.array(df_ER.level.values.astype(int))\n",
        "rationales = np.array(df_ER.rationale_labels.values.tolist())\n",
        "\n",
        "ER_model = Model()\n",
        "# IN_model = Model()\n",
        "# EX_model = Model()\n",
        "\n",
        "optimizer_model = tfa.optimizers.AdamW(\n",
        "    weight_decay=1e-2, # not given but default in py torch so probably used\n",
        "    learning_rate=2e-5, # given\n",
        "    epsilon=1e-8 # given\n",
        ")\n",
        "\n",
        "# ER_model.compile(optimizer=optimizer_model)"
      ],
      "execution_count": 179,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZbyGRCtYivp3"
      },
      "source": [
        "# train_dataset = tf.data.Dataset(input_ids_SP, attention_masks_SP, input_ids_RP, attention_masks_RP, labels, rationales)\n",
        "train_dataset = [input_ids_SP, attention_masks_SP, input_ids_RP, attention_masks_RP, labels, rationales]\n",
        "train_size = int(len(train_dataset))\n",
        "\n",
        "total_steps = train_size * 4 # 4 is epoch\n",
        "# num_batch = int(train_size / 32) # 32 is batch size\n",
        "\n",
        "tf.random.set_seed(12) # given seed"
      ],
      "execution_count": 152,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "2SqYT52kkPSS",
        "outputId": "d5ebb06a-f593-4687-ca6b-ca1428dbb15b"
      },
      "source": [
        "for epoch in range(0, 4):\n",
        "  print(\"Training epoch #\", epoch, \"...\")\n",
        "  total_train_loss = 0\n",
        "  total_train_empathy_loss = 0\n",
        "  total_train_rationale_loss = 0\n",
        "\n",
        "  # ER_model.train()\n",
        "\n",
        "  for i in range(len(train_dataset[0])):\n",
        "  # for element in train_dataset:\n",
        "      e_id_SP = train_dataset[0][i] # get seeker id \n",
        "      e_attention_SP = train_dataset[1][i] # get seeker attention \n",
        "      e_id_RP = train_dataset[2][i] # get response id \n",
        "      e_attention_RP = train_dataset[3][i] # get response attention\n",
        "      e_labels = train_dataset[4][i] # get labels\n",
        "      e_rationales = train_dataset[5][i] # get rationales\n",
        "\n",
        "      loss, loss_empathy, loss_rationale, logits_empathy, logits_rationale = ER_model.forward(\n",
        "          input_ids_SP=e_id_SP,\n",
        "          input_ids_RP=e_id_RP,\n",
        "          attention_mask_SP=e_attention_SP,\n",
        "          attention_mask_RP=e_attention_RP,\n",
        "          empathy_labels=e_labels,\n",
        "          rationale_labels=e_rationales,\n",
        "          SP=df_ER.seeker_post,\n",
        "          RP=df_ER.response_post\n",
        "          )\n",
        "      \n",
        "      total_train_loss += loss\n",
        "      total_train_empathy_loss += loss_empathy\n",
        "      total_train_rationale_loss += loss_rationale\n",
        "\n",
        "      optimizer_model.minimize(loss) # update optimizer\n",
        "\n",
        "      print(loss)\n",
        "    \n",
        "  print(\"Epoch #\", epoch)\n",
        "  print(\"Total loss:\", total_train_loss)\n",
        "  print(\"Total empathy loss:\", total_train_empathy_loss)\n",
        "  print(\"Total rationale loss:\", total_train_rationale_loss)"
      ],
      "execution_count": 176,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training epoch # 0 ...\n",
            "mul\n",
            "divide\n",
            "softmax\n",
            "other mul\n",
            "attention\n",
            "here\n",
            "mul\n",
            "divide\n",
            "softmax\n",
            "other mul\n",
            "attention\n",
            "here\n",
            "mul\n",
            "divide\n",
            "softmax\n",
            "other mul\n",
            "attention\n",
            "here\n",
            "mul\n",
            "divide\n",
            "softmax\n",
            "other mul\n",
            "attention\n",
            "here\n",
            "mul\n",
            "divide\n",
            "softmax\n",
            "other mul\n",
            "attention\n",
            "here\n",
            "mul\n",
            "divide\n",
            "softmax\n",
            "other mul\n",
            "attention\n",
            "here\n",
            "mul\n",
            "divide\n",
            "softmax\n",
            "other mul\n",
            "attention\n",
            "here\n",
            "mul\n",
            "divide\n",
            "softmax\n",
            "other mul\n",
            "attention\n",
            "here\n",
            "mul\n",
            "divide\n",
            "softmax\n",
            "other mul\n",
            "attention\n",
            "here\n",
            "mul\n",
            "divide\n",
            "softmax\n",
            "other mul\n",
            "attention\n",
            "here\n",
            "mul\n",
            "divide\n",
            "softmax\n",
            "other mul\n",
            "attention\n",
            "here\n",
            "mul\n",
            "divide\n",
            "softmax\n",
            "other mul\n",
            "attention\n",
            "here\n",
            "mul\n",
            "divide\n",
            "softmax\n",
            "other mul\n",
            "attention\n",
            "here\n",
            "mul\n",
            "divide\n",
            "softmax\n",
            "other mul\n",
            "attention\n",
            "here\n",
            "mul\n",
            "divide\n",
            "softmax\n",
            "other mul\n",
            "attention\n",
            "here\n",
            "mul\n",
            "divide\n",
            "softmax\n",
            "other mul\n",
            "attention\n",
            "here\n",
            "mul\n",
            "divide\n",
            "softmax\n",
            "other mul\n",
            "attention\n",
            "here\n",
            "mul\n",
            "divide\n",
            "softmax\n",
            "other mul\n",
            "attention\n",
            "here\n",
            "mul\n",
            "divide\n",
            "softmax\n",
            "other mul\n",
            "attention\n",
            "here\n",
            "mul\n",
            "divide\n",
            "softmax\n",
            "other mul\n",
            "attention\n",
            "here\n",
            "mul\n",
            "divide\n",
            "softmax\n",
            "other mul\n",
            "attention\n",
            "here\n",
            "mul\n",
            "divide\n",
            "softmax\n",
            "other mul\n",
            "attention\n",
            "here\n",
            "mul\n",
            "divide\n",
            "softmax\n",
            "other mul\n",
            "attention\n",
            "here\n",
            "mul\n",
            "divide\n",
            "softmax\n",
            "other mul\n",
            "attention\n",
            "here\n",
            "mul\n",
            "divide\n",
            "softmax\n",
            "other mul\n",
            "attention\n",
            "here\n",
            "mul\n",
            "divide\n",
            "softmax\n",
            "other mul\n",
            "attention\n",
            "here\n",
            "mul\n",
            "divide\n",
            "softmax\n",
            "other mul\n",
            "attention\n",
            "here\n",
            "mul\n",
            "divide\n",
            "softmax\n",
            "other mul\n",
            "attention\n",
            "here\n",
            "mul\n",
            "divide\n",
            "softmax\n",
            "other mul\n",
            "attention\n",
            "here\n",
            "mul\n",
            "divide\n",
            "softmax\n",
            "other mul\n",
            "attention\n",
            "here\n",
            "mul\n",
            "divide\n",
            "softmax\n",
            "other mul\n",
            "attention\n",
            "here\n",
            "mul\n",
            "divide\n",
            "softmax\n",
            "other mul\n",
            "attention\n",
            "here\n",
            "mul\n",
            "divide\n",
            "softmax\n",
            "other mul\n",
            "attention\n",
            "here\n",
            "mul\n",
            "divide\n",
            "softmax\n",
            "other mul\n",
            "attention\n",
            "here\n",
            "mul\n",
            "divide\n",
            "softmax\n",
            "other mul\n",
            "attention\n",
            "here\n",
            "mul\n",
            "divide\n",
            "softmax\n",
            "other mul\n",
            "attention\n",
            "here\n",
            "mul\n",
            "divide\n",
            "softmax\n",
            "other mul\n",
            "attention\n",
            "here\n",
            "mul\n",
            "divide\n",
            "softmax\n",
            "other mul\n",
            "attention\n",
            "here\n",
            "mul\n",
            "divide\n",
            "softmax\n",
            "other mul\n",
            "attention\n",
            "here\n",
            "mul\n",
            "divide\n",
            "softmax\n",
            "other mul\n",
            "attention\n",
            "here\n",
            "mul\n",
            "divide\n",
            "softmax\n",
            "other mul\n",
            "attention\n",
            "here\n",
            "mul\n",
            "divide\n",
            "softmax\n",
            "other mul\n",
            "attention\n",
            "here\n",
            "mul\n",
            "divide\n",
            "softmax\n",
            "other mul\n",
            "attention\n",
            "here\n",
            "mul\n",
            "divide\n",
            "softmax\n",
            "other mul\n",
            "attention\n",
            "here\n",
            "mul\n",
            "divide\n",
            "softmax\n",
            "other mul\n",
            "attention\n",
            "here\n",
            "mul\n",
            "divide\n",
            "softmax\n",
            "other mul\n",
            "attention\n",
            "here\n",
            "mul\n",
            "divide\n",
            "softmax\n",
            "other mul\n",
            "attention\n",
            "here\n",
            "mul\n",
            "divide\n",
            "softmax\n",
            "other mul\n",
            "attention\n",
            "here\n",
            "mul\n",
            "divide\n",
            "softmax\n",
            "other mul\n",
            "attention\n",
            "here\n",
            "mul\n",
            "divide\n",
            "softmax\n",
            "other mul\n",
            "attention\n",
            "here\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "TypeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-176-ca1b3255d8fc>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     24\u001b[0m           \u001b[0mrationale_labels\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0me_rationales\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     25\u001b[0m           \u001b[0mSP\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdf_ER\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mseeker_post\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 26\u001b[0;31m           \u001b[0mRP\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdf_ER\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresponse_post\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     27\u001b[0m           )\n\u001b[1;32m     28\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-174-3301e054a27d>\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input_ids_SP, input_ids_RP, attention_mask_SP, attention_mask_RP, token_type_ids_SP, token_type_ids_RP, position_ids_SP, position_ids_RP, head_mask_SP, head_mask_RP, inputs_embeds_SP, inputs_embeds_RP, empathy_labels, rationale_labels, lambda_EI, lambda_RE, SP, RP)\u001b[0m\n\u001b[1;32m     67\u001b[0m       \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"here\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     68\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 69\u001b[0;31m     \u001b[0mlogits_empathy\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mempathy_classifier\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     70\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     71\u001b[0m     \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdropout\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mTypeError\u001b[0m: list indices must be integers or slices, not tuple"
          ]
        }
      ]
    }
  ]
}